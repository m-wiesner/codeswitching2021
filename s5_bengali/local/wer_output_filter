#!/usr/bin/env python3

# 2021 Dongji Gao
# Apache 2.0.

import argparse
import sys
import io
import unicodedata


infile = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
output = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


def _has_charset(w, s):
    for c in w:
        try:
            if unicodedata.name(c).startswith(s):
                return True
        except:
            continue
    return False


# creates a dictionary that maps Bengali-English words.
def get_filter_dict(trans_book):
    filter_dict = dict()

    with open(trans_book, 'r', encoding='utf-8') as tb:
        for line in tb.readlines():
            beng_word, eng_word = line.rstrip().split(None, 1)
            if _has_charset(eng_word, "BENGALI"):
                tmp = beng_word
                beng_word = eng_word
                eng_word = tmp
            if beng_word not in filter_dict:
                filter_dict[beng_word] = eng_word
    return filter_dict
            

# replace bengali word in the utterance with english word or viseversa
def filter(filter_dict):
    for line in infile:
        output_list = list()
        for word in line.rstrip().split():
            if word in filter_dict:
                output_list.append(filter_dict[word])
            else:
                output_list.append(word)
        print(" ".join(output_list), file=output)
        
def analysis():
    pass

def main():
    trans_book = 'local/bengali_english_all'
    filter_dict = get_filter_dict(trans_book)
    filter(filter_dict)
    analysis()


if __name__ == "__main__":
    main()
